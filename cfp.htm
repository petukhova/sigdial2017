<html>

<head>
<meta http-equiv="Content-Language" content="en-us">
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<link rel="stylesheet" type="text/css" href="sigdial2010.css">
<title>SIGDIAL 2017 - Call for Papers</title>
</head>

<body>
<div id="wrapper">
<div id="body">
<div id="main">

<!--
<h1>Call for Papers (TBA)</h1>
-->

<h1 align="left">SIGDIAL 2017 CONFERENCE<br>
August 15-17, 2017</h1>

<p><font face="Arial">
The 18th Annual Meeting of the Special Interest
Group on Discourse and Dialogue, <a href="http://www.uni-saarland.de/en/home.html" 
target="_blank">Saarland University</a>, Saarbrücken, Germany. August 15-17, 2017 (before INTERSPEECH).
</p>

<p><font face="Arial">
The SIGDIAL venue provides a regular forum for the presentation of
cutting edge research in discourse and dialogue to both academic and
industry researchers. Continuing with a series of successful seventeen
<a href="http://www.sigdial.org/sigdial-meetings" 
target="_blank">previous meetings</a>, this conference spans the research interest area of
discourse and dialogue. The conference is sponsored by <a href="http://www.sigdial.org/" 
target="_blank">the SIGdial organization</a>, which serves as 
the Special Interest Group in discourse and dialogue for
both <a href="http://www.aclweb.org/" target="_blank">ACL</a>
and <a href="http://www.isca-speech.org/" target="_blank">ISCA</a>. SIGDIAL 2017 will be co-located
with <a href="http://www.saardial.uni-saarland.de/" target="_blank">SaarDial (SemDial 2017)</a>, and will be held immediately after <a href="http://www.yrrsds.org" target="_blank">YRRSDS 2017</a>, the Young
Researchers' Roundtable on Spoken Dialog Systems and before <a href="http://interspeech2017.org//" target="_blank">INTERSPEECH 2017</a>.
</p><br>

<h3>TOPICS OF INTEREST</h3>
<p><font face="Arial">
We welcome formal, corpus-based, implementation, experimental, or analytical work on discourse and dialogue including, but not
restricted to, the following themes:
<ul>
    <li><b>Discourse Processing and Dialogue Systems</b><br>
	Discourse semantic and pragmatic issues in NLP applications such as
text summarization, question answering, and information retrieval.<br>
Spoken, multi-modal, and text/web based dialogue systems, their
components, evaluation and applications.<br>

    <li><b>Corpora, Tools and Methodology</b><br> 
	Corpus-based and experimental work on discourse and spoken, text-based
and multi-modal dialogue, including supporting topics such as annotation tools and schemes, and corpora.<br>

    <li><b>Pragmatic and/or Semantic Modeling</b><br>
	The pragmatics and/or semantics of discourse and dialogue (i.e. beyond
a single sentence).
</ul>
</p><br>

<!--
<h3>SPECIAL SESSIONS</h3>
<p><font face="Arial">
We also welcome papers to special sessions. A SIGDIAL special session
has the length of a regular session at the conference and may be
organized as a poster session, a poster session with panel discussion,
or an oral presentation session. The papers submitted to special
sessions are handled by special session organizers, but for the
submitted papers to be in the SIGDIAL proceedings, they have to
undergo the same review process as regular papers. The deadline for
special session proposals is on 1 March, 2017. The accepted special
sessions will be announced on 10 March, 2017. 
</p>


<h3>SUBMISSIONS</h3>

<b>Special Session Proposals</b><br>
<p><font face="Arial" color="red">
Submission of special session proposals is now closed.
<p><font face="Arial" color="black">
The SIGDIAL organizers welcome the submission of special session proposals. 
A SIGDIAL special session is the length of a regular session at the conference; 
may be organized as a poster session, a poster session with panel discussion, 
or an oral presentation session; and will be held on the last day of the 
conference. Special sessions may, at the discretion of the SIGDIAL organizers, 
be held as parallel sessions. Those wishing to organize a special session 
should prepare a two-page proposal containing: a summary of the topic of the 
special session; a list of organizers and sponsors; a list of people who may 
submit and participate; and a requested format (poster/panel/oral session).  
These proposals should be sent to conference[at]sigdial.org by the special 
session proposal deadline. Special session proposals will be reviewed jointly 
by the general and program co-chairs.</p>

<p><b>Papers</b><br>
<!--<p><font face="Arial" color="red">
Submission of papers is now closed.
<p><font face="Arial" color="black">
The program committee welcomes the submission of long papers, short
papers and demo descriptions. Papers submitted as long papers may be
accepted as long papers for oral presentation, long papers for poster
presentation, or short papers for poster presentation. Short papers
will be presented as posters.</p>

<ul>
    <li> Long papers must be no longer than eight pages, including title,
  text, figures and tables. An unlimited number of pages are allowed
  for references. Two additional pages are allowed for example
  discourses or dialogues and algorithms. 

    <li>Short papers should be no longer than four pages including title,
  text, figures and tables. An unlimited number of pages are allowed
  for references.

    <li>Demo descriptions should be no longer than four pages including
  title, text, examples, figures, tables and references.
</ul>

<p>Authors are encouraged to also submit additional accompanying
materials such as corpora (or corpus examples), demo code, videos,
sound files, etc.
</p>

<p>Please use the official ACL style files: <a href="http://acl2016.org/files/acl2016.zip">ACL 2016 style guidelines</a></p>.

<!--<p>Authors of a submission may designate their paper to be considered for a 
SIGDIAL special session, which would highlight a particular area or topic.  
All papers will undergo regular peer review.</p>

<p>Papers that have been or will be submitted to other meetings or
publications must provide this information (see submission
format). SIGDIAL 2016 cannot accept for publication or presentation
work that will be (or has been) published elsewhere. Any questions
regarding submissions can be sent to program-chairs<at>sigdial.org.</p>


<p>Submission link: To be announced</p>
<!--<p>Submission is electronic using paper submission software at:
<a href="https://www.softconf.com/e/sigdial2014/" target=top>https://www.softconf.com/e/sigdial2014/</a>.</p>-->


<!--<h3>FORMAT</h3>
<p><font face="Arial">
All long, short, and demonstration submissions should follow the two-column 
ACL 2014 format. 
We strongly recommend the use of ACL LaTeX style files or Microsoft Word style 
files tailored for the 
ACL 2014 conference. 
Submissions must conform to the official ACL 2014 style guidelines 
<a href="http://www.cs.jhu.edu/ACL2014/CallforPapers.htm" target="_blank">
ACL 2014 style guidelines</a>, and they must be electronic in PDF. 
<p>
<b>As in most previous years, submissions will not be anonymous. Papers may include authors' names and affiliations, and self-references are allowed.</b>
</p>-->


<h3>MENTORING</h3>
<p><font face="Arial">
Submissions with innovative core ideas that may be in need of language
(English) or organizational assistance will be flagged for "mentoring"
and accepted with recommendation to revise with a mentor. An
experienced mentor who has previously published in the SIGDIAL venue
will then help the authors of these flagged papers prepare their
submissions for publication. 
<!--Any questions about this initiative can
be addressed to the mentoring chair Pierre Lison (University of Oslo,
Norway plison@ifi.uio.no).
-->
</p>

<!--<h3>STUDENT SUPPORT</h3>
<p><font face="Arial">
SIGDIAL also offers a limited number of scholarships for students presenting
a paper accepted to the conference. Application materials will be posted
at the conference website.</p>-->

<h3>BEST PAPER AWARDS</h3>
<p><font face="Arial">
In order to recognize significant advancements in dialog/discourse
science and technology, SIGDIAL will recognize BEST PAPER AWARDs. All
papers at the conference are eligible for the best paper awards. A
selection committee consisting of prominent researchers in the fields
of interest will select the recipients of the awards.</p>

<!--<h3>SPONSOR THE CONFERENCE</h3>
<p><font face="Arial">
SIGDIAL offers a number of opportunities for sponsors. For more information, 
email the sponshorships chair Giuseppe Di Fabbrizio at 
sponsor-chair[at]sigdial.org.
</p>-->

<br>

<!--<h3>DIALOGUE AND DISCOURSE</h3>
<p><font face="Arial">
SIGDIAL authors are encouraged to submit their research to the journal 
Dialogue and Discourse, which is endorsed by SIGdial.</p>-->

<!--<h3>IMPORTANT DATES</h3>

<table class="info">
  <tr>
    <th colspan="2">Important Dates</td>
  </tr>
  <tr>
    <td>Special Session Proposal Deadline</td>
    <td>1 March, 2016 (23:59, GMT-11)</td>
  </tr>
  <tr>
    <td>Special Session Notification</td>
    <td>27 March, 2016</td>
  </tr>
  <tr>
    <td>Long, Short and Demonstration Paper Submission Deadline</td>
    <td>15 May, 2016 (23:59, GMT-11)</td>
  </tr>
  <tr>
    <td>Long, Short and Demonstration Paper Notification</td>
    <td>28 June, 2016</td>
  </tr>
  <!--<tr>
    <td>Final Paper Submission Deadline (mentored papers only)</td>
    <td><del>Wednesday, 14 May 2014</del></td>
  </tr>
  <tr>
    <td>Final Paper Submission Deadline </td>
    <td>21 July, 2016</td>
  </tr>
  <tr>
    <td class="highlight"><b>Conference</b></td>
    <td>13-15 Sept, 2016</td>
  </tr>
</table>-->

<br><br>



<!--<h3 style="margin-bottom:0">Program Committee</h3>
<table>
  <tr><td>TBA</td></tr>
  <!-- <tr><td>Jan Alexandersson, DFKI GmbH, Germany</td></tr>
  <tr><td>Masahiro Araki, Kyoto Institute of Technology, Japan</td></tr>
  <tr><td>Yasuo Ariki, Kobe University, Japan</td></tr>
  <tr><td>Ron Artstein, University of Southern California, USA</td></tr>
  <tr><td>Timo Baumann, Universitat Hamburg, Germany</td></tr>
  <tr><td>Frederic Bechet, Aix Marseille Universite - LIF/CNRS, France</td></tr>
  <tr><td>Steve Beet, Aculab plc, UK</td></tr>
  <tr><td>Jose Miguel Benedi, Universitat Politecnica de Valencia, Spain</td></tr>
  <tr><td>Luciana Benotti, Universidad Nacional de Cordoba, Argentina</td></tr>
  <tr><td>Nicole Beringer, 3SOFT GmbH, Germany</td></tr>	
  <tr><td>Nate Blaylock, Nuance Communications, Canada</td></tr>
  <tr><td>Dan Bohus, Microsoft Research, USA</td></tr>
  <tr><td>Johan Boye, KTH, Sweden</td></tr>
  <tr><td>Kristy Boyer, North Carolina State University, USA</td></tr>
  <tr><td>Asli Celikyilmaz, Microsoft, USA</td></tr>
  <tr><td>Christophe Cerisara, CNRS, France</td></tr>
  <tr><td>Joyce Chai, Michigan State University, USA</td></tr>
  <tr><td>Mark Core, University of Southern California, USA</td></tr>
  <tr><td>Paul Crook, Microsoft, USA</td></tr>
  <tr><td>Heriberto Cuay&aacute;huitl, Heriot-Watt University, Edinburgh, UK</td></tr>
  <tr><td>Xiaodong Cui, IBM T. J. Watson Research Center, USA</td></tr>
  <tr><td>Marie-Catherine de Marneffe, Ohio State University, USA</td></tr>
  <tr><td>David DeVault, University of Southern California, USA</td></tr>
  <tr><td>Barbara Di Eugenio, University of Illinois at Chicago, USA</td></tr>
  <tr><td>Giuseppe Di Fabbrizio, Amazon.com, USA</td></tr>
  <tr><td>Dimitrios Dimitriadis, AT&amp;T Labs Research, USA</td></tr>
  <tr><td>Myroslava Dzikovska, University of Edinburgh, UK</td></tr>
  <tr><td>Jens Edlund, KTH Speech Music and Hearing, Sweden</td></tr>
  <tr><td>Mauro Falcone, Fondazione Ugo Bordoni, Italy</td></tr>
  <tr><td>Benoit Favre, Aix-Marseille Universite - LIF/CNRS, France</td></tr>
  <tr><td>Raquel Fern&aacute;ndez, ILLC, University of Amsterdam, Netherlands</td></tr>
  <tr><td>Claire Gardent, CNRS/LORIA, Nancy, France</td></tr>
  <tr><td>Kallirroi Georgila, University of Southern California, USA</td></tr>
  <tr><td>Panayiotis Georgiou, University of Southern California, USA</td></tr>
  <tr><td>Agustin Gravano, Universidad de Buenos Aires, Argentina</td></tr>
  <tr><td>Nancy Green, University of North Carolina Greensboro, USA</td></tr>
  <tr><td>Curry Guinn, University of North Carolina at Wilmington, USA</td></tr>
  <tr><td>Dilek Hakkani-Tur, Microsoft Research, USA</td></tr>
  <tr><td>Mark Hasegawa-Johnson, University of Illinois at Urbana-Champaign, USA</td></tr>
  <tr><td>Helen Hastie, Heriot-Watt University, Edinburgh, UK</td></tr> 
  <tr><td>Peter Heeman, Oregon Health and Sciences University, Center for Spoken Language Understanding, USA</td></tr>
  <tr><td>Keikichi Hirose, University of Tokyo, Japan</td></tr>
  <tr><td>David Janiszek, Universite Paris Descartes, France</td></tr>
  <tr><td>Kristiina Jokinen, University of Helsinki, Finland</td></tr>
  <tr><td>Arne Jonsson, Linkoping University, Sweden</td></tr>
  <tr><td>Pamela Jordan, University of Pittsburgh, USA</td></tr>
  <tr><td>Tatsuya Kawahara, Kyoto University, Japan</td></tr>
  <tr><td>Simon Keizer, Heriot-Watt University, Edinburgh, UK</td></tr>
  <tr><td>Norihide Kitaoka, Nagoya University, Japan</td></tr>
  <tr><td>Kazunori Komatani, Nagoya University, Japan</td></tr>
  <tr><td>Stefan Kopp, Bielefeld University, Germany</td></tr>
  <tr><td>Ian Lane, Carnegie Mellon University, USA</td></tr>
  <tr><td>Romain Laroche, Orange Labs, France</td></tr>
  <tr><td>Alex Lascarides, University of Edinburgh, UK</td></tr>
  <tr><td>Sungjin Lee, Language Technologies Institute, Carnegie Mellon University, USA</td></tr>
  <tr><td>Gary Geunbae Lee, POSTECH, South Korea</td></tr>
  <tr><td>Fabrice Lefevre, University of Avignon, France</td></tr>
  <tr><td>Oliver Lemon, Heriot-Watt University, Edinburgh, UK</td></tr>
  <tr><td>James Lester, North Carolina State University, USA</td></tr>
  <tr><td>Diane Litman, University of Pittsburgh, USA</td></tr>
  <tr><td>Eduardo Lleida Solano, University of Zaragoza, Spain</td></tr>
  <tr><td>Ramon Lopez-Cozar, University of Granada, Spain</td></tr>
  <tr><td>Annie Louis, University of Edinburgh, UK</td></tr>
  <tr><td>Hugo Meinedo, INESC-ID Lisboa, Portugal</td></tr>
  <tr><td>Helen Meng, The Chinese University of Hong Kong, Hong Kong Special Administrative Region of China</td></tr>
  <tr><td>Florian Metze, Carnegie Mellon University, USA</td></tr>
  <tr><td>Wolfgang Minker, Ulm University, Germany</td></tr>
  <tr><td>Teruhisa Misu, Honda Research Institute USA, USA</td></tr>
  <tr><td>Mikio Nakano, Honda Research Institute Japan, Japan</td></tr>
  <tr><td>Ani Nenkova, University of Pennsylvania, USA</td></tr>
  <tr><td>Vincent Ng, University of Texas at Dallas, USA</td></tr>
  <tr><td>Elmar Noeth, Friedrich-Alexander-University Erlangen-Nuremberg, Germany</td></tr>
  <tr><td>Douglas O'Shaughnessy, INRS-EMT (University of Quebec), Canada</td></tr>
  <tr><td>Paul Piwek, The Open University, UK</td></tr>
  <tr><td>Andrei Popescu-Belis, Idiap Research Institute, Switzerland</td></tr>
  <tr><td>Matthew Purver, Queen Mary, University of London, UK</td></tr>
  <tr><td>Antoine Raux, Lenovo Labs, USA</td></tr>
  <tr><td>Norbert Reithinger, DFKI GmbH, Germany</td></tr>
  <tr><td>Verena Rieser, Heriot-Watt University, Edinburgh, UK</td></tr>
  <tr><td>Carolyn Rose, Carnegie Mellon University, USA</td></tr>
  <tr><td>Alexander Rudnicky, Carnegie Mellon University, USA</td></tr>
  <tr><td>David Schlangen, Bielefeld University, Germany</td></tr>
  <tr><td>Gabriel Skantze, KTH Speech Music and Hearing, Sweden</td></tr>
  <tr><td>Manfred Stede, University of Potsdam, Germany</td></tr>
  <tr><td>Georg Stemmer, Intel Corp., Germany</td></tr>
  <tr><td>Amanda Stent, Yahoo! Labs, USA</td></tr>
  <tr><td>Matthew Stone, Rutgers, The State University of New Jersey, USA</td></tr>
  <tr><td>Svetlana Stoyanchev, AT&amp;T Labs Research, USA</td></tr>
  <tr><td>Kristina Striegnitz, Union College, USA</td></tr>
  <tr><td>Marc Swerts, Tilburg University, Netherlands</td></tr>
  <tr><td>Antonio Teixeira, University of Aveiro, Portugal</td></tr>
  <tr><td>Joel Tetreault, Yahoo! Labs, USA</td></tr>
  <tr><td>Takenobu Tokunaga, Tokyo Institute of Technology, Japan</td></tr>
  <tr><td>Isabel Trancoso, INESC-ID / IST, Portugal</td></tr>
  <tr><td>David Traum, University of Southern California, USA</td></tr>
  <tr><td>Gokhan Tur, Microsoft Research, USA</td></tr>
  <tr><td>Renata Vieira, PUCRS, Brazil</td></tr>
  <tr><td>Marilyn Walker, University of California Santa Cruz, USA</td></tr>
  <tr><td>Hsin-Min Wang, Academia Sinica, Taiwan</td></tr>
  <tr><td>Nigel Ward, University of Texas at El Paso, USA</td></tr>
  <tr><td>Jason Williams, Microsoft Research, USA</td></tr>
  <tr><td>Steve Young, Cambridge University, UK</td></tr>
  <tr><td>Kai Yu, Shanghai Jiao Tong University, China</td></tr>
  <tr><td>Jian Zhang, Dongguan University of Technology and the Hong Kong University of Science and Technology, China</td></tr>
</table>-->


<br><br><br>
<font face="Arial">Last update:</font> December 23, 2016 - <a href="credits.htm">Credits</a>

</div>
</div>
</div>
</body>
</html>
